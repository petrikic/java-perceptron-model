# Java Perceptron Model

Inspirado nos neur√¥nios do c√©rebro humano, o ***perceptron*** √© um modelo matem√°tico que recebe v√°rias entradas, e devolve uma √∫nica sa√≠da bin√°ria. A sa√≠da do neur√¥nio, √© determinada pela soma ponderada ***Œ£jwjxj***, sendo menor ou maior que um valor de limiar.

## üöÄ Come√ßando

* Primeiro, voc√™ deve clonar o reposit√≥rio do projeto. No terminal de sua prefer√™ncia, utilize o comando `git clone https://github.com/petrikic/java-perceptron-model`

### üìã Pr√©-requisitos

Para utilizar o software, voc√™ vai precisar instalar:
* [Java Development Kit](https://www.oracle.com/br/java/technologies/javase-downloads.html) - *`vers√£o 1.8 ou superior`*.

### üîß Instala√ß√£o

* Com o diret√≥rio do projeto aberto em um terminal de sua prefer√™ncia, rode o comando `javac Perceptron.java Main.java` para gerar o bitecode do projeto.

* Em seguida, rode o comando `java Main` para executar o projeto.

* Digite a op√ß√£o desejada, e insira as informa√ß√µes necess√°rias.

## üì¶ Implementa√ß√£o

* Calculo da sa√≠da: Foi uilizado a somat√≥ria do produto das entradas pelos seus respectivos pesos, como tamb√©m do bias pelo seu respectivo peso. O resultado da somat√≥ria, passa por uma fun√ß√£o de ativa√ß√£o, que nesse caso, √© a fun√ß√£o degrau (0 para sum < 0, e 1 para sum >= 0).

* C√°lculo de atualiza√ß√£o dos pesos: Foi utilizada para a atuali√ß√£o dos pesos a regra delta ( *`Wi = Wi + n * (d(k) - y) * X(k)`* ), que soma o valor contido no peso, ao produto da taxa de aprendizagem, pelo produto do calculo do erro, pelo produto da sa√≠da esperada (`tamb√©m chamado de classe`).

* treinamento da rede: Para efetuar o treinamento, √© recebido um conjunto de dados de entrada, juntamente com um conjunto de dados de saidas esperadas. Inicialmente, temos um loop do tipo do while, que repete todo o c√≠clo de treinamento, at√© que a rede n√£o produza mais erros nas saidas para todos os casos. Em seu n√≠vel interno, temos um loop do tipo for, que itera a cada conjunto de entradas, juntamente com o seu conjunto de saidas esperadas. e por fim, temos outro loop do tipo do while, que repete o c√≠clo at√© que o caso de testes atual n√£o produza mais erros. Nele, calculamos o erro pela diferen√ßa entre entre a sa√≠da gerada pela rede, e a sa√≠da esperada ( *`d(k) - y`* ). Logo ap√≥s, chamamos o m√©todo de atualiza√ß√£o dos pesos. Caso o calculo do erro seja diferente de zero, todo processo √© repetido. Se o calculo do erro for igual a zero, prosseguimos com os pr√≥ximos casos de teste.

## üìà Limita√ß√µes
Muito embora o projeto seja extremamente divertido, e possa lidar tranquilamente com problemas como simular portas `NOT`, `AND`, `OR`, `NAND`, e `NOR`, ele acaba tendo algumas dificuldades na resolu√ß√£o de problemas mais complexos, como o `XOR`, por exemplo. Isso ocorre por conta da limita√ß√£o da utiliza√ß√£o de apenas um neur√¥nio na rede. Para esses casos, √© poss√≠vel solucionar o problema utilizando o modelo de `Perceptron Multi Camadas`.

## üõ†Ô∏è Constru√≠do com

* [Visual Studio Code](https://code.visualstudio.com/) - *`a IDE utilizada no projeto.`*


## ‚úíÔ∏è Autor

* [**Cleriston Nantes Petrikic**](https://github.com/linkParaPerfil)

## üìÑ Licen√ßa

Este projeto est√° sob a licen√ßa MIT - veja o arquivo [LICENSE](https://github.com/petrikic/java-perceptron-model/blob/master/LICENSE) para detalhes.
